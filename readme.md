# Data Engineering - End-to-End ETL Framework with Python, S3, and SES

This is an end-to-end project with two main goals.
To Extract, Transform, and Load (ETL) a file from a source using Amazon AWS S3 storage, Redshift, PostgreSQL,SQL Server, and Teradata, and to load it into Redshift, PostgreSQL,SQL Server, and Teradata, as well as extract files.
Implement Data Quality (DQ) validation, including row and profile rules, then notify the user of any issues detected.

## Solution Architecture Overview

<img width="926" alt="flow" src="https://github.com/imtheguna/integration_pipeline_framework/assets/58139175/408032f7-26ec-47b2-8058-9a6aac96c0fc">


Medium Story - https://medium.com/@imtheguna/53cf6d571a6c

#### Project Created & Maintained By

#### Gunanithi CS

Passionate #Flutter, #ETL. #UI Designer #Data Engineer


<a href="https://www.linkedin.com/in/imtheguna/"><img src="https://raw.githubusercontent.com/aritraroy/social-icons/master/linkedin-icon.png" alt="linkedin"  width="60"></a> <a href="https://medium.com/@imtheguna"><img src="https://raw.githubusercontent.com/aritraroy/social-icons/master/medium-icon.png" alt="medium" width="60"></a>

## Notes
Please [open an issue](https://github.com/imtheguna/integration_pipeline_framework/issues) if you find any bugs.

#### Donate

You like the package ? Buy me a coffee :)

<a href="https://www.buymeacoffee.com/imtheguna" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/default-orange.png" alt="Buy Me A Coffee" height="41" width="174"></a>
